{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chainer\n",
    "from chainer import cuda, Function, gradient_check, Variable, \\\n",
    "                        optimizers, serializers, utils\n",
    "from chainer import Link, Chain, ChainList\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "\n",
    "from chainer.utils import walker_alias\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set data\n",
    "\n",
    "index2word = {}\n",
    "word2index = {}\n",
    "counts = collections.Counter()\n",
    "dataset = []\n",
    "with open('ptb.train.txt') as f:\n",
    "    for line in f:\n",
    "        for word in line.split():\n",
    "            if word not in word2index:\n",
    "                ind = len(word2index)\n",
    "                word2index[word] = ind\n",
    "                index2word[ind] = word\n",
    "            counts[word2index[word]] += 1\n",
    "            dataset.append(word2index[word])\n",
    "\n",
    "n_vocab = len(word2index)\n",
    "datasize = len(dataset)\n",
    "\n",
    "cs = [counts[w] for w in range(len(counts))]\n",
    "power = np.float32(0.75)\n",
    "p = np.array(cs, power.dtype)\n",
    "sampler = walker_alias.WalkerAlias(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "\n",
    "class MyW2V(chainer.Chain):\n",
    "    def __init__(self, n_vocab, n_units):\n",
    "        super(MyW2V, self).__init__(\n",
    "            embed=L.EmbedID(n_vocab, n_units),\n",
    "        )\n",
    "    def __call__(self, xb, yb, tb):\n",
    "        xc = Variable(np.array(xb, dtype=np.int32))\n",
    "        yc = Variable(np.array(yb, dtype=np.int32))\n",
    "        tc = Variable(np.array(tb, dtype=np.int32))\n",
    "        return F.sigmoid_cross_entropy(self.fwd(xc,yc), tc)\n",
    "    def fwd(self, x, y):\n",
    "        x1 = self.embed(x)\n",
    "        x2 = self.embed(y)\n",
    "        return F.sum(x1 * x2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# my functions\n",
    "\n",
    "ws = 3         ### window size\n",
    "ngs = 5        ### negative sample size\n",
    "\n",
    "def mkbatset(dataset, ids):\n",
    "    xb, yb, tb = [], [], []\n",
    "    for pos in ids:\n",
    "        xid = dataset[pos]\n",
    "        for i in range(1,ws):\n",
    "            p = pos - i\n",
    "            if p >= 0:\n",
    "                xb.append(xid)\n",
    "                yid = dataset[p]\n",
    "                yb.append(yid)\n",
    "                tb.append(1)\n",
    "                for nid in sampler.sample(ngs):\n",
    "                    xb.append(yid)\n",
    "                    yb.append(nid)\n",
    "                    tb.append(0)\n",
    "            p = pos + i\n",
    "            if p < datasize:\n",
    "                xb.append(xid)\n",
    "                yid = dataset[p]\n",
    "                yb.append(yid)\n",
    "                tb.append(1)\n",
    "                for nid in sampler.sample(ngs):\n",
    "                    xb.append(yid)\n",
    "                    yb.append(nid)\n",
    "                    tb.append(0)\n",
    "    return [xb, yb, tb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "\n",
    "demb = 100\n",
    "model = MyW2V(n_vocab, demb)\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "epoch: 1\n",
      "epoch: 2\n",
      "epoch: 3\n",
      "epoch: 4\n",
      "epoch: 5\n",
      "epoch: 6\n",
      "epoch: 7\n",
      "epoch: 8\n",
      "epoch: 9\n"
     ]
    }
   ],
   "source": [
    "# Learn\n",
    "\n",
    "bs = 100\n",
    "for epoch in range(10):\n",
    "    print('epoch: {0}'.format(epoch))\n",
    "    indexes = np.random.permutation(datasize)\n",
    "    for pos in range(0, datasize, bs):\n",
    "        # print (epoch, pos)\n",
    "        ids = indexes[pos:(pos+bs) if (pos+bs) < datasize else datasize]\n",
    "        xb, yb, tb = mkbatset(dataset, ids)\n",
    "        model.zerograds()\n",
    "        loss = model(xb, yb, tb)\n",
    "        loss.backward()\n",
    "        optimizer.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open('w2v.model', 'w') as f:\n",
    "    f.write('%d %d\\n' % (len(index2word), 100))\n",
    "    w = model.embed.W.data\n",
    "    for i in range(w.shape[0]):\n",
    "        v = ' '.join(['%f' % v for v in w[i]])\n",
    "        f.write('%s %s\\n' % (index2word[i], v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
