{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import codecs\n",
    "import collections\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xp = np\n",
    "\n",
    "#n_epoch = 400       # number of epochs\n",
    "n_epoch = 5\n",
    "n_units = 30        # number of units per layer\n",
    "batchsize = 25     # minibatch size\n",
    "n_label = 5         # number of labels\n",
    "epoch_per_eval = 5  # number of epochs per evaluation\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SexpParser(object):\n",
    "\n",
    "    def __init__(self, line):\n",
    "        self.tokens = re.findall(r'\\(|\\)|[^\\(\\) ]+', line)\n",
    "        self.pos = 0\n",
    "\n",
    "    def parse(self):\n",
    "        assert self.pos < len(self.tokens)\n",
    "        token = self.tokens[self.pos]\n",
    "        assert token != ')'\n",
    "        self.pos += 1\n",
    "\n",
    "        if token == '(':\n",
    "            children = []\n",
    "            while True:\n",
    "                assert self.pos < len(self.tokens)\n",
    "                if self.tokens[self.pos] == ')':\n",
    "                    self.pos += 1\n",
    "                    break\n",
    "                else:\n",
    "                    children.append(self.parse())\n",
    "            return children\n",
    "        else:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_tree(vocab, exp):\n",
    "    assert isinstance(exp, list) and (len(exp) == 2 or len(exp) == 3)\n",
    "\n",
    "    if len(exp) == 2:\n",
    "        label, leaf = exp\n",
    "        if leaf not in vocab:\n",
    "            vocab[leaf] = len(vocab)\n",
    "        return {'label': int(label), 'node': vocab[leaf]}\n",
    "    elif len(exp) == 3:\n",
    "        label, left, right = exp\n",
    "        node = (convert_tree(vocab, left), convert_tree(vocab, right))\n",
    "        return {'label': int(label), 'node': node}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(path, vocab, max_size):\n",
    "    with codecs.open(path, encoding='utf-8') as f:\n",
    "        trees = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            tree = SexpParser(line).parse()\n",
    "            trees.append(convert_tree(vocab, tree))\n",
    "            if max_size and len(trees) >= max_size:\n",
    "                break\n",
    "\n",
    "        return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "line (3 (2 (2 The) (2 Rock)) (4 (3 (2 is) (4 (2 destined) (2 (2 (2 (2 (2 to) (2 (2 be) (2 (2 the) (2 (2 21st) (2 (2 (2 Century) (2 's)) (2 (3 new) (2 (2 ``) (2 Conan)))))))) (2 '')) (2 and)) (3 (2 that) (3 (2 he) (3 (2 's) (3 (2 going) (3 (2 to) (4 (3 (2 make) (3 (3 (2 a) (3 splash)) (2 (2 even) (3 greater)))) (2 (2 than) (2 (2 (2 (2 (1 (2 Arnold) (2 Schwarzenegger)) (2 ,)) (2 (2 Jean-Claud) (2 (2 Van) (2 Damme)))) (2 or)) (2 (2 Steven) (2 Segal))))))))))))) (2 .)))\n",
      "tokens ['(', '3', '(', '2', '(', '2', 'The', ')', '(', '2', 'Rock', ')', ')', '(', '4', '(', '3', '(', '2', 'is', ')', '(', '4', '(', '2', 'destined', ')', '(', '2', '(', '2', '(', '2', '(', '2', '(', '2', 'to', ')', '(', '2', '(', '2', 'be', ')', '(', '2', '(', '2', 'the', ')', '(', '2', '(', '2', '21st', ')', '(', '2', '(', '2', '(', '2', 'Century', ')', '(', '2', \"'s\", ')', ')', '(', '2', '(', '3', 'new', ')', '(', '2', '(', '2', '``', ')', '(', '2', 'Conan', ')', ')', ')', ')', ')', ')', ')', ')', '(', '2', \"''\", ')', ')', '(', '2', 'and', ')', ')', '(', '3', '(', '2', 'that', ')', '(', '3', '(', '2', 'he', ')', '(', '3', '(', '2', \"'s\", ')', '(', '3', '(', '2', 'going', ')', '(', '3', '(', '2', 'to', ')', '(', '4', '(', '3', '(', '2', 'make', ')', '(', '3', '(', '3', '(', '2', 'a', ')', '(', '3', 'splash', ')', ')', '(', '2', '(', '2', 'even', ')', '(', '3', 'greater', ')', ')', ')', ')', '(', '2', '(', '2', 'than', ')', '(', '2', '(', '2', '(', '2', '(', '2', '(', '1', '(', '2', 'Arnold', ')', '(', '2', 'Schwarzenegger', ')', ')', '(', '2', ',', ')', ')', '(', '2', '(', '2', 'Jean-Claud', ')', '(', '2', '(', '2', 'Van', ')', '(', '2', 'Damme', ')', ')', ')', ')', '(', '2', 'or', ')', ')', '(', '2', '(', '2', 'Steven', ')', '(', '2', 'Segal', ')', ')', ')', ')', ')', ')', ')', ')', ')', ')', ')', ')', ')', '(', '2', '.', ')', ')', ')']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['(', ' ', ' ', ' ', ' ', ')']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# play ground\n",
    "# train_trees = read_corpus('trees/train.txt', vocab, max_size)\n",
    "with codecs.open('trees/train.txt',  encoding='utf-8') as f:\n",
    "    trees = []\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        print(\"line\", line)\n",
    "        tokens = re.findall(r'\\(|\\)|[^\\(\\) ]+', line)\n",
    "        print(\"tokens\", tokens)        \n",
    "        pos = 0\n",
    "        \n",
    "        \n",
    "        assert self.pos < len(self.tokens)\n",
    "        token = self.tokens[self.pos]\n",
    "        assert token != ')'\n",
    "        self.pos += 1\n",
    "\n",
    "        if token == '(':\n",
    "            children = []\n",
    "            while True:\n",
    "                assert self.pos < len(self.tokens)\n",
    "                if self.tokens[self.pos] == ')':\n",
    "                    self.pos += 1\n",
    "                    break\n",
    "                else:\n",
    "                    children.append(self.parse())\n",
    "            return print(\"children\", children)\n",
    "        else:\n",
    "            print(\"token\", token)\n",
    "        \n",
    "        break\n",
    "\n",
    "#re.findall(r'\\(|\\)|[^\\(\\) ]+', \"( line , abc, def)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecursiveNet(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_vocab, n_units):\n",
    "        super(RecursiveNet, self).__init__(\n",
    "            embed=L.EmbedID(n_vocab, n_units),\n",
    "            l=L.Linear(n_units * 2, n_units),\n",
    "            w=L.Linear(n_units, n_label))\n",
    "\n",
    "    def leaf(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "    def node(self, left, right):\n",
    "        return F.tanh(self.l(F.concat((left, right))))\n",
    "\n",
    "    def label(self, v):\n",
    "        return self.w(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverse(model, node, train=True, evaluate=None, root=True):\n",
    "    if isinstance(node['node'], int):\n",
    "        # leaf node\n",
    "        word = xp.array([node['node']], np.int32)\n",
    "        loss = 0\n",
    "        x = chainer.Variable(word, volatile=not train)\n",
    "        v = model.leaf(x)\n",
    "    else:\n",
    "        # internal node\n",
    "        left_node, right_node = node['node']\n",
    "        left_loss, left = traverse(\n",
    "            model, left_node, train=train, evaluate=evaluate, root=False)\n",
    "        right_loss, right = traverse(\n",
    "            model, right_node, train=train, evaluate=evaluate, root=False)\n",
    "        v = model.node(left, right)\n",
    "        loss = left_loss + right_loss\n",
    "\n",
    "    y = model.label(v)\n",
    "\n",
    "    if train:\n",
    "        label = xp.array([node['label']], np.int32)\n",
    "        t = chainer.Variable(label, volatile=not train)\n",
    "        loss += F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    if evaluate is not None:\n",
    "        predict = cuda.to_cpu(y.data.argmax(1))\n",
    "        if predict[0] == node['label']:\n",
    "            evaluate['correct_node'] += 1\n",
    "        evaluate['total_node'] += 1\n",
    "\n",
    "        if root:\n",
    "            if predict[0] == node['label']:\n",
    "                evaluate['correct_root'] += 1\n",
    "            evaluate['total_root'] += 1\n",
    "\n",
    "    return loss, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_trees):\n",
    "    m = model.copy()\n",
    "    m.volatile = True\n",
    "    result = collections.defaultdict(lambda: 0)\n",
    "    for tree in test_trees:\n",
    "        traverse(m, tree, train=False, evaluate=result)\n",
    "\n",
    "    acc_node = 100.0 * result['correct_node'] / result['total_node']\n",
    "    acc_root = 100.0 * result['correct_root'] / result['total_root']\n",
    "    print(' Node accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
    "        acc_node, result['correct_node'], result['total_node']))\n",
    "    print(' Root accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
    "        acc_root, result['correct_root'], result['total_root']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "max_size = None\n",
    "train_trees = read_corpus('trees/train.txt', vocab, max_size)\n",
    "test_trees = read_corpus('trees/test.txt', vocab, max_size)\n",
    "develop_trees = read_corpus('trees/dev.txt', vocab, max_size)\n",
    "\n",
    "model = RecursiveNet(len(vocab), n_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = optimizers.AdaGrad(lr=0.1)\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accum_loss = 0\n",
    "count = 0\n",
    "start_at = time.time()\n",
    "cur_at = start_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 3,\n",
       " 'node': ({'label': 2,\n",
       "   'node': ({'label': 2, 'node': 0}, {'label': 2, 'node': 1})},\n",
       "  {'label': 4,\n",
       "   'node': ({'label': 3,\n",
       "     'node': ({'label': 2, 'node': 2},\n",
       "      {'label': 4,\n",
       "       'node': ({'label': 2, 'node': 3},\n",
       "        {'label': 2,\n",
       "         'node': ({'label': 2,\n",
       "           'node': ({'label': 2,\n",
       "             'node': ({'label': 2,\n",
       "               'node': ({'label': 2, 'node': 4},\n",
       "                {'label': 2,\n",
       "                 'node': ({'label': 2, 'node': 5},\n",
       "                  {'label': 2,\n",
       "                   'node': ({'label': 2, 'node': 6},\n",
       "                    {'label': 2,\n",
       "                     'node': ({'label': 2, 'node': 7},\n",
       "                      {'label': 2,\n",
       "                       'node': ({'label': 2,\n",
       "                         'node': ({'label': 2, 'node': 8},\n",
       "                          {'label': 2, 'node': 9})},\n",
       "                        {'label': 2,\n",
       "                         'node': ({'label': 3, 'node': 10},\n",
       "                          {'label': 2,\n",
       "                           'node': ({'label': 2, 'node': 11},\n",
       "                            {'label': 2, 'node': 12})})})})})})})},\n",
       "              {'label': 2, 'node': 13})},\n",
       "            {'label': 2, 'node': 14})},\n",
       "          {'label': 3,\n",
       "           'node': ({'label': 2, 'node': 15},\n",
       "            {'label': 3,\n",
       "             'node': ({'label': 2, 'node': 16},\n",
       "              {'label': 3,\n",
       "               'node': ({'label': 2, 'node': 9},\n",
       "                {'label': 3,\n",
       "                 'node': ({'label': 2, 'node': 17},\n",
       "                  {'label': 3,\n",
       "                   'node': ({'label': 2, 'node': 4},\n",
       "                    {'label': 4,\n",
       "                     'node': ({'label': 3,\n",
       "                       'node': ({'label': 2, 'node': 18},\n",
       "                        {'label': 3,\n",
       "                         'node': ({'label': 3,\n",
       "                           'node': ({'label': 2, 'node': 19},\n",
       "                            {'label': 3, 'node': 20})},\n",
       "                          {'label': 2,\n",
       "                           'node': ({'label': 2, 'node': 21},\n",
       "                            {'label': 3, 'node': 22})})})},\n",
       "                      {'label': 2,\n",
       "                       'node': ({'label': 2, 'node': 23},\n",
       "                        {'label': 2,\n",
       "                         'node': ({'label': 2,\n",
       "                           'node': ({'label': 2,\n",
       "                             'node': ({'label': 2,\n",
       "                               'node': ({'label': 1,\n",
       "                                 'node': ({'label': 2, 'node': 24},\n",
       "                                  {'label': 2, 'node': 25})},\n",
       "                                {'label': 2, 'node': 26})},\n",
       "                              {'label': 2,\n",
       "                               'node': ({'label': 2, 'node': 27},\n",
       "                                {'label': 2,\n",
       "                                 'node': ({'label': 2, 'node': 28},\n",
       "                                  {'label': 2, 'node': 29})})})},\n",
       "                            {'label': 2, 'node': 30})},\n",
       "                          {'label': 2,\n",
       "                           'node': ({'label': 2, 'node': 31},\n",
       "                            {'label': 2, 'node': 32})})})})})})})})})})})})},\n",
       "    {'label': 2, 'node': 33})})}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# play ground\n",
    "# isinstance(train_trees[0]['node'], int)\n",
    "\n",
    "train_trees[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss: 223760.15\n",
      "5.46 iters/sec, 1563.50 sec\n",
      "\n",
      "Epoch: 1\n",
      "loss: 159683.95\n",
      "7.01 iters/sec, 1219.45 sec\n",
      "\n",
      "Epoch: 2\n",
      "loss: 136041.59\n",
      "6.60 iters/sec, 1293.73 sec\n",
      "\n",
      "Epoch: 3\n",
      "loss: 122566.20\n",
      "8.40 iters/sec, 1017.21 sec\n",
      "\n",
      "Epoch: 4\n",
      "loss: 113496.38\n",
      "7.75 iters/sec, 1102.12 sec\n",
      "\n",
      "Train data evaluation:\n",
      " Node accuracy: 86.60 %% (275,885/318,582)\n",
      " Root accuracy: 53.97 %% (4,611/8,544)\n",
      "Develop data evaluation:\n",
      " Node accuracy: 80.32 %% (33,291/41,447)\n",
      " Root accuracy: 42.96 %% (473/1,101)\n",
      "\n",
      "Test evaluateion\n",
      " Node accuracy: 80.04 %% (66,109/82,600)\n",
      " Root accuracy: 41.36 %% (914/2,210)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    print('Epoch: {0:d}'.format(epoch))\n",
    "    total_loss = 0\n",
    "    cur_at = time.time()\n",
    "    random.shuffle(train_trees)\n",
    "    for tree in train_trees:\n",
    "        loss, v = traverse(model, tree, train=True)\n",
    "        accum_loss += loss\n",
    "        count += 1\n",
    "\n",
    "        if count >= batchsize:\n",
    "            model.zerograds()\n",
    "            accum_loss.backward()\n",
    "            optimizer.update()\n",
    "            total_loss += float(accum_loss.data)\n",
    "\n",
    "            accum_loss = 0\n",
    "            count = 0\n",
    "\n",
    "    print('loss: {:.2f}'.format(total_loss))\n",
    "\n",
    "    now = time.time()\n",
    "    throuput = float(len(train_trees)) / (now - cur_at)\n",
    "    print('{:.2f} iters/sec, {:.2f} sec'.format(throuput, now - cur_at))\n",
    "    print()\n",
    "\n",
    "    if (epoch + 1) % epoch_per_eval == 0:\n",
    "        print('Train data evaluation:')\n",
    "        evaluate(model, train_trees)\n",
    "        print('Develop data evaluation:')\n",
    "        evaluate(model, develop_trees)\n",
    "        print('')\n",
    "\n",
    "print('Test evaluateion')\n",
    "evaluate(model, test_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import serializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# serializers.save_npz(\"sentiment.model\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "load_model = RecursiveNet(len(vocab), n_units)\n",
    "optimizer = optimizers.AdaGrad(lr=0.1)\n",
    "optimizer.setup(load_model)\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n",
    "serializers.load_npz('sentiment.model',  load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = load_model.copy()\n",
    "m.volatile = True\n",
    "result = collections.defaultdict(lambda: 0)\n",
    "train = False\n",
    "result = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# traverse(m, train_trees[1], train=False, evaluate=result)\n",
    "node = train_trees[2]\n",
    "if isinstance(node['node'], int):\n",
    "    # leaf node\n",
    "    word = xp.array([node['node']], np.int32)\n",
    "    loss = 0\n",
    "    x = chainer.Variable(word, volatile=not train)\n",
    "    v = load_model.leaf(x)\n",
    "else:\n",
    "    # internal node\n",
    "    left_node, right_node = node['node']\n",
    "    left_loss, left = traverse(\n",
    "        load_model, left_node, train=train, evaluate=result, root=False)\n",
    "    right_loss, right = traverse(\n",
    "        load_model, right_node, train=train, evaluate=result, root=False)\n",
    "    v = load_model.node(left, right)\n",
    "    loss = left_loss + right_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {'correct_node': 68, 'total_node': 76})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6064]\n",
      "[6064]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.32051429,  0.36132571,  0.04742519,  0.2816264 , -0.29773203,\n",
       "        -0.01792988,  0.28714287,  0.14204991, -0.27863452,  0.05220072,\n",
       "         0.27659449,  0.29560179,  0.1171884 ,  0.3331736 , -0.45720482,\n",
       "         0.31917858,  0.28488305,  0.30823752, -0.29386976,  0.21543735,\n",
       "        -0.31053305, -0.31920785,  0.3124949 , -0.18925038,  0.34076777,\n",
       "         0.29246122,  0.32320318,  0.31434807,  0.18184373,  0.34562123]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_trees[2]\n",
    "\n",
    "word = xp.array([test_trees[0]['node'][0]['node'][0]['node']], np.int32)\n",
    "loss = 0\n",
    "x = chainer.Variable(word, volatile=not train)\n",
    "v = load_model.leaf(x)\n",
    "print(word)\n",
    "print(x.data)\n",
    "v.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6064"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
