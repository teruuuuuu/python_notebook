{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import codecs\n",
    "import collections\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "from chainer import cuda\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xp = np\n",
    "\n",
    "#n_epoch = 400       # number of epochs\n",
    "n_epoch = 5\n",
    "n_units = 30        # number of units per layer\n",
    "batchsize = 25     # minibatch size\n",
    "n_label = 5         # number of labels\n",
    "epoch_per_eval = 5  # number of epochs per evaluation\n",
    "test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SexpParser(object):\n",
    "\n",
    "    def __init__(self, line):\n",
    "        self.tokens = re.findall(r'\\(|\\)|[^\\(\\) ]+', line)\n",
    "        self.pos = 0\n",
    "\n",
    "    def parse(self):\n",
    "        assert self.pos < len(self.tokens)\n",
    "        token = self.tokens[self.pos]\n",
    "        assert token != ')'\n",
    "        self.pos += 1\n",
    "\n",
    "        if token == '(':\n",
    "            children = []\n",
    "            while True:\n",
    "                assert self.pos < len(self.tokens)\n",
    "                if self.tokens[self.pos] == ')':\n",
    "                    self.pos += 1\n",
    "                    break\n",
    "                else:\n",
    "                    children.append(self.parse())\n",
    "            return children\n",
    "        else:\n",
    "            return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_tree(vocab, exp):\n",
    "    assert isinstance(exp, list) and (len(exp) == 2 or len(exp) == 3)\n",
    "\n",
    "    if len(exp) == 2:\n",
    "        label, leaf = exp\n",
    "        if leaf not in vocab:\n",
    "            vocab[leaf] = len(vocab)\n",
    "        return {'label': int(label), 'node': vocab[leaf]}\n",
    "    elif len(exp) == 3:\n",
    "        label, left, right = exp\n",
    "        node = (convert_tree(vocab, left), convert_tree(vocab, right))\n",
    "        return {'label': int(label), 'node': node}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_corpus(path, vocab, max_size):\n",
    "    with codecs.open(path, encoding='utf-8') as f:\n",
    "        trees = []\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            tree = SexpParser(line).parse()\n",
    "            trees.append(convert_tree(vocab, tree))\n",
    "            if max_size and len(trees) >= max_size:\n",
    "                break\n",
    "\n",
    "        return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RecursiveNet(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_vocab, n_units):\n",
    "        super(RecursiveNet, self).__init__(\n",
    "            embed=L.EmbedID(n_vocab, n_units),\n",
    "            l=L.Linear(n_units * 2, n_units),\n",
    "            w=L.Linear(n_units, n_label))\n",
    "\n",
    "    def leaf(self, x):\n",
    "        return self.embed(x)\n",
    "\n",
    "    def node(self, left, right):\n",
    "        return F.tanh(self.l(F.concat((left, right))))\n",
    "\n",
    "    def label(self, v):\n",
    "        return self.w(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverse(model, node, train=True, evaluate=None, root=True):\n",
    "    if isinstance(node['node'], int):\n",
    "        # leaf node\n",
    "        word = xp.array([node['node']], np.int32)\n",
    "        loss = 0\n",
    "        x = chainer.Variable(word, volatile=not train)\n",
    "        v = model.leaf(x)\n",
    "    else:\n",
    "        # internal node\n",
    "        left_node, right_node = node['node']\n",
    "        left_loss, left = traverse(\n",
    "            model, left_node, train=train, evaluate=evaluate, root=False)\n",
    "        right_loss, right = traverse(\n",
    "            model, right_node, train=train, evaluate=evaluate, root=False)\n",
    "        v = model.node(left, right)\n",
    "        loss = left_loss + right_loss\n",
    "\n",
    "    y = model.label(v)\n",
    "\n",
    "    if train:\n",
    "        label = xp.array([node['label']], np.int32)\n",
    "        t = chainer.Variable(label, volatile=not train)\n",
    "        loss += F.softmax_cross_entropy(y, t)\n",
    "\n",
    "    if evaluate is not None:\n",
    "        predict = cuda.to_cpu(y.data.argmax(1))\n",
    "        if predict[0] == node['label']:\n",
    "            evaluate['correct_node'] += 1\n",
    "        evaluate['total_node'] += 1\n",
    "\n",
    "        if root:\n",
    "            if predict[0] == node['label']:\n",
    "                evaluate['correct_root'] += 1\n",
    "            evaluate['total_root'] += 1\n",
    "\n",
    "    return loss, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_trees):\n",
    "    m = model.copy()\n",
    "    m.volatile = True\n",
    "    result = collections.defaultdict(lambda: 0)\n",
    "    for tree in test_trees:\n",
    "        traverse(m, tree, train=False, evaluate=result)\n",
    "\n",
    "    acc_node = 100.0 * result['correct_node'] / result['total_node']\n",
    "    acc_root = 100.0 * result['correct_root'] / result['total_root']\n",
    "    print(' Node accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
    "        acc_node, result['correct_node'], result['total_node']))\n",
    "    print(' Root accuracy: {0:.2f} %% ({1:,d}/{2:,d})'.format(\n",
    "        acc_root, result['correct_root'], result['total_root']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "max_size = None\n",
    "train_trees = read_corpus('trees/train.txt', vocab, max_size)\n",
    "test_trees = read_corpus('trees/test.txt', vocab, max_size)\n",
    "develop_trees = read_corpus('trees/dev.txt', vocab, max_size)\n",
    "\n",
    "model = RecursiveNet(len(vocab), n_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup optimizer\n",
    "optimizer = optimizers.AdaGrad(lr=0.1)\n",
    "optimizer.setup(model)\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accum_loss = 0\n",
    "count = 0\n",
    "start_at = time.time()\n",
    "cur_at = start_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "loss: 223760.15\n",
      "5.46 iters/sec, 1563.50 sec\n",
      "\n",
      "Epoch: 1\n",
      "loss: 159683.95\n",
      "7.01 iters/sec, 1219.45 sec\n",
      "\n",
      "Epoch: 2\n",
      "loss: 136041.59\n",
      "6.60 iters/sec, 1293.73 sec\n",
      "\n",
      "Epoch: 3\n",
      "loss: 122566.20\n",
      "8.40 iters/sec, 1017.21 sec\n",
      "\n",
      "Epoch: 4\n",
      "loss: 113496.38\n",
      "7.75 iters/sec, 1102.12 sec\n",
      "\n",
      "Train data evaluation:\n",
      " Node accuracy: 86.60 %% (275,885/318,582)\n",
      " Root accuracy: 53.97 %% (4,611/8,544)\n",
      "Develop data evaluation:\n",
      " Node accuracy: 80.32 %% (33,291/41,447)\n",
      " Root accuracy: 42.96 %% (473/1,101)\n",
      "\n",
      "Test evaluateion\n",
      " Node accuracy: 80.04 %% (66,109/82,600)\n",
      " Root accuracy: 41.36 %% (914/2,210)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epoch):\n",
    "    print('Epoch: {0:d}'.format(epoch))\n",
    "    total_loss = 0\n",
    "    cur_at = time.time()\n",
    "    random.shuffle(train_trees)\n",
    "    for tree in train_trees:\n",
    "        loss, v = traverse(model, tree, train=True)\n",
    "        accum_loss += loss\n",
    "        count += 1\n",
    "\n",
    "        if count >= batchsize:\n",
    "            model.zerograds()\n",
    "            accum_loss.backward()\n",
    "            optimizer.update()\n",
    "            total_loss += float(accum_loss.data)\n",
    "\n",
    "            accum_loss = 0\n",
    "            count = 0\n",
    "\n",
    "    print('loss: {:.2f}'.format(total_loss))\n",
    "\n",
    "    now = time.time()\n",
    "    throuput = float(len(train_trees)) / (now - cur_at)\n",
    "    print('{:.2f} iters/sec, {:.2f} sec'.format(throuput, now - cur_at))\n",
    "    print()\n",
    "\n",
    "    if (epoch + 1) % epoch_per_eval == 0:\n",
    "        print('Train data evaluation:')\n",
    "        evaluate(model, train_trees)\n",
    "        print('Develop data evaluation:')\n",
    "        evaluate(model, develop_trees)\n",
    "        print('')\n",
    "\n",
    "print('Test evaluateion')\n",
    "evaluate(model, test_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from chainer import serializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "serializers.save_npz(\"sentiment.model\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the model\n",
    "load_model = RecursiveNet(len(vocab), n_units)\n",
    "optimizer = optimizers.AdaGrad(lr=0.1)\n",
    "optimizer.setup(load_model)\n",
    "optimizer.add_hook(chainer.optimizer.WeightDecay(0.0001))\n",
    "serializers.load_npz('sentiment.model',  load_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = load_model.copy()\n",
    "m.volatile = True\n",
    "result = collections.defaultdict(lambda: 0)\n",
    "train = False\n",
    "result = collections.defaultdict(lambda: 0)\n",
    "\n",
    "# traverse(m, train_trees[1], train=False, evaluate=result)\n",
    "node = train_trees[2]\n",
    "if isinstance(node['node'], int):\n",
    "    # leaf node\n",
    "    word = xp.array([node['node']], np.int32)\n",
    "    loss = 0\n",
    "    x = chainer.Variable(word, volatile=not train)\n",
    "    v = load_model.leaf(x)\n",
    "else:\n",
    "    # internal node\n",
    "    left_node, right_node = node['node']\n",
    "    left_loss, left = traverse(\n",
    "        load_model, left_node, train=train, evaluate=result, root=False)\n",
    "    right_loss, right = traverse(\n",
    "        load_model, right_node, train=train, evaluate=result, root=False)\n",
    "    v = load_model.node(left, right)\n",
    "    loss = left_loss + right_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>>,\n",
       "            {'correct_node': 39, 'total_node': 48})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 3,\n",
       " 'node': ({'label': 2, 'node': 3909},\n",
       "  {'label': 4,\n",
       "   'node': ({'label': 3,\n",
       "     'node': ({'label': 3,\n",
       "       'node': ({'label': 1,\n",
       "         'node': ({'label': 2, 'node': 6},\n",
       "          {'label': 2,\n",
       "           'node': ({'label': 1, 'node': 1545}, {'label': 2, 'node': 3910})})},\n",
       "        {'label': 2,\n",
       "         'node': ({'label': 2, 'node': 37},\n",
       "          {'label': 3,\n",
       "           'node': ({'label': 2,\n",
       "             'node': ({'label': 2, 'node': 19},\n",
       "              {'label': 3,\n",
       "               'node': ({'label': 2, 'node': 3911},\n",
       "                {'label': 2, 'node': 316})})},\n",
       "            {'label': 3,\n",
       "             'node': ({'label': 2, 'node': 93},\n",
       "              {'label': 2,\n",
       "               'node': ({'label': 2,\n",
       "                 'node': ({'label': 2, 'node': 6},\n",
       "                  {'label': 2,\n",
       "                   'node': ({'label': 2, 'node': 1789},\n",
       "                    {'label': 2, 'node': 3912})})},\n",
       "                {'label': 2,\n",
       "                 'node': ({'label': 2, 'node': 37},\n",
       "                  {'label': 2,\n",
       "                   'node': ({'label': 2, 'node': 6},\n",
       "                    {'label': 2, 'node': 3913})})})})})})})},\n",
       "      {'label': 2, 'node': 63})},\n",
       "    {'label': 3,\n",
       "     'node': ({'label': 2, 'node': 3049},\n",
       "      {'label': 2,\n",
       "       'node': ({'label': 3,\n",
       "         'node': ({'label': 2,\n",
       "           'node': ({'label': 2,\n",
       "             'node': ({'label': 2, 'node': 2675}, {'label': 2, 'node': 323})},\n",
       "            {'label': 2, 'node': 1277})},\n",
       "          {'label': 2,\n",
       "           'node': ({'label': 2,\n",
       "             'node': ({'label': 2, 'node': 82},\n",
       "              {'label': 2,\n",
       "               'node': ({'label': 2, 'node': 37},\n",
       "                {'label': 2, 'node': 124})})},\n",
       "            {'label': 2, 'node': 3914})})},\n",
       "        {'label': 2, 'node': 490})})})})}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_trees[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
