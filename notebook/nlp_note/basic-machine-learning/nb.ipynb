{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents: 4, vocabularies: 6, categories: 2\n",
      "P(Chinese|yes) =  0.42857142857142855\n",
      "P(Tokyo|yes) =  0.07142857142857142\n",
      "P(Japan|yes) =  0.07142857142857142\n",
      "P(Chinese|no) =  0.2222222222222222\n",
      "P(Tokyo|no) =  0.2222222222222222\n",
      "P(Japan|no) =  0.2222222222222222\n",
      "log P(yes|test) = -8.10769031284391\n",
      "log P(no|test) = -8.906681345001262\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "#coding:utf-8\n",
    "import math\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayes:\n",
    "    \"\"\"Multinomial Naive Bayes\"\"\"\n",
    "    def __init__(self):\n",
    "        self.categories = set()     # カテゴリの集合\n",
    "        self.vocabularies = set()   # ボキャブラリの集合\n",
    "        self.wordcount = {}         # wordcount[cat][word] カテゴリでの単語の出現回数\n",
    "        self.catcount = {}          # catcount[cat] カテゴリの出現回数\n",
    "        self.denominator = {}       # denominator[cat] P(word|cat)の分母の値\n",
    "    \n",
    "    def train(self, data):\n",
    "        \"\"\"ナイーブベイズ分類器の訓練\"\"\"\n",
    "        # 文書集合からカテゴリを抽出して辞書を初期化\n",
    "        for d in data:\n",
    "            cat = d[0]\n",
    "            self.categories.add(cat)\n",
    "        for cat in self.categories:\n",
    "            self.wordcount[cat] = defaultdict(int)\n",
    "            self.catcount[cat] = 0\n",
    "        # 文書集合からカテゴリと単語をカウント\n",
    "        for d in data:\n",
    "            cat, doc = d[0], d[1:]\n",
    "            self.catcount[cat] += 1\n",
    "            for word in doc:\n",
    "                self.vocabularies.add(word)\n",
    "                self.wordcount[cat][word] += 1\n",
    "        # 単語の条件付き確率の分母の値をあらかじめ一括計算しておく（高速化のため）\n",
    "        for cat in self.categories:\n",
    "            self.denominator[cat] = sum(self.wordcount[cat].values()) + len(self.vocabularies)\n",
    "    \n",
    "    def classify(self, doc):\n",
    "        \"\"\"事後確率の対数 log(P(cat|doc)) がもっとも大きなカテゴリを返す\"\"\"\n",
    "        best = None\n",
    "        max = -sys.maxsize\n",
    "        for cat in self.catcount.keys():\n",
    "            p = self.score(doc, cat)\n",
    "            if p > max:\n",
    "                max = p\n",
    "                best = cat\n",
    "        return best\n",
    "    \n",
    "    def wordProb(self, word, cat):\n",
    "        \"\"\"単語の条件付き確率 P(word|cat) を求める\"\"\"\n",
    "        # ラプラススムージングを適用\n",
    "        # wordcount[cat]はdefaultdict(int)なのでカテゴリに存在しなかった単語はデフォルトの0を返す\n",
    "        # 分母はtrain()の最後で一括計算済み\n",
    "        return float(self.wordcount[cat][word] + 1) / float(self.denominator[cat])\n",
    "    \n",
    "    def score(self, doc, cat):\n",
    "        \"\"\"文書が与えられたときのカテゴリの事後確率の対数 log(P(cat|doc)) を求める\"\"\"\n",
    "        total = sum(self.catcount.values())  # 総文書数\n",
    "        score = math.log(float(self.catcount[cat]) / total)  # log P(cat)\n",
    "        for word in doc:\n",
    "            # logをとるとかけ算は足し算になる\n",
    "            score += math.log(self.wordProb(word, cat))  # log P(word|cat)\n",
    "        return score\n",
    "    \n",
    "    def __str__(self):\n",
    "        total = sum(self.catcount.values())  # 総文書数\n",
    "        return \"documents: %d, vocabularies: %d, categories: %d\" % (total, len(self.vocabularies), len(self.categories))\n",
    "\n",
    "\n",
    "# Introduction to Information Retrieval 13.2の例題\n",
    "data = [[\"yes\", \"Chinese\", \"Beijing\", \"Chinese\"],\n",
    "        [\"yes\", \"Chinese\", \"Chinese\", \"Shanghai\"],\n",
    "        [\"yes\", \"Chinese\", \"Macao\"],\n",
    "        [\"no\", \"Tokyo\", \"Japan\", \"Chinese\"]]\n",
    "# ナイーブベイズ分類器を訓練\n",
    "nb = NaiveBayes()\n",
    "nb.train(data)\n",
    "print (nb)\n",
    "print (\"P(Chinese|yes) = \", nb.wordProb(\"Chinese\", \"yes\"))\n",
    "print (\"P(Tokyo|yes) = \", nb.wordProb(\"Tokyo\", \"yes\"))\n",
    "print (\"P(Japan|yes) = \", nb.wordProb(\"Japan\", \"yes\"))\n",
    "print (\"P(Chinese|no) = \", nb.wordProb(\"Chinese\", \"no\"))\n",
    "print (\"P(Tokyo|no) = \", nb.wordProb(\"Tokyo\", \"no\"))\n",
    "print (\"P(Japan|no) = \", nb.wordProb(\"Japan\", \"no\"))\n",
    "# テストデータのカテゴリを予測\n",
    "test = [\"Chinese\", \"Chinese\", \"Chinese\", \"Tokyo\", \"Japan\"]\n",
    "print (\"log P(yes|test) =\", nb.score(test, \"yes\"))\n",
    "print (\"log P(no|test) =\", nb.score(test, \"no\"))\n",
    "print (nb.classify(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3]\n",
      "[1]\n",
      "[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arimuraterutoshi/.pyenv/versions/anaconda3-2.4.1/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/arimuraterutoshi/.pyenv/versions/anaconda3-2.4.1/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n",
      "/Users/arimuraterutoshi/.pyenv/versions/anaconda3-2.4.1/lib/python3.5/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import GaussianNB # ガウシアン\n",
    "X = np.array([[1,2,3,4,5,6,7,8],\n",
    "              [1,1,3,4,5,6,6,7],\n",
    "              [2,1,2,4,5,8,8,8]]) # 特徴ベクトル\n",
    "y = np.array([1, 2, 3]) # そのラベル\n",
    "t = np.array([2,2,4,5,6,8,8,8]) # テストデータ\n",
    "\n",
    "clf = GaussianNB() # 正規分布を仮定したベイズ分類\n",
    "clf.fit(X, y) # 学習をする\n",
    "print(clf.predict(t))\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB #ベルヌーイ\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(t) )\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB #多項分布\n",
    "clf = MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "clf.fit(X, y)\n",
    "print(clf.predict(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
