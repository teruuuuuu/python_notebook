{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "  \"\"\"Multinomial Naive Bayes\"\"\"\n",
    "  def __init__(self):\n",
    "    self.categories = set()     # カテゴリの集合\n",
    "    self.vocabularies = set()   # ボキャブラリの集合\n",
    "    self.wordcount = {}         # wordcount[cat][word] カテゴリでの単語の出現回数\n",
    "    self.catcount = {}          # catcount[cat] カテゴリの出現回数\n",
    "    self.denominator = {}       # denominator[cat] P(word|cat)の分母の値\n",
    "  \n",
    "  def train(self, data):\n",
    "    \"\"\"ナイーブベイズ分類器の訓練\"\"\"\n",
    "    # 文書集合からカテゴリを抽出して辞書を初期化\n",
    "    for d in data:\n",
    "      cat = d[0]\n",
    "      self.categories.add(cat)\n",
    "    for cat in self.categories:\n",
    "      self.wordcount[cat] = defaultdict(int)\n",
    "      self.catcount[cat] = 0\n",
    "    # 文書集合からカテゴリと単語をカウント\n",
    "    for d in data:\n",
    "      cat, doc = d[0], d[1:]\n",
    "      self.catcount[cat] += 1\n",
    "      for word in doc:\n",
    "        self.vocabularies.add(word)\n",
    "        self.wordcount[cat][word] += 1\n",
    "    # 単語の条件付き確率の分母の値をあらかじめ一括計算しておく（高速化のため）\n",
    "    for cat in self.categories:\n",
    "      self.denominator[cat] = sum(self.wordcount[cat].values()) + len(self.vocabularies)\n",
    " \n",
    "  def classify(self, doc):\n",
    "    \"\"\"事後確率の対数 log(P(cat|doc)) がもっとも大きなカテゴリを返す\"\"\"\n",
    "    best = None\n",
    "    max = -sys.maxsize\n",
    "    for cat in self.catcount.keys():\n",
    "      p = self.scoreCount(doc, cat)\n",
    "      if p > max:\n",
    "        max = p\n",
    "        best = cat\n",
    "    return best\n",
    "\n",
    "  def wordProb(self, word, cat):\n",
    "    \"\"\"単語の条件付き確率 P(word|cat) を求める\"\"\"\n",
    "    # ラプラススムージングを適用\n",
    "    # wordcount[cat]はdefaultdict(int)なのでカテゴリに存在しなかった単語はデフォルトの0を返す\n",
    "    # 分母はtrain()の最後で一括計算済み\n",
    "    return float(self.wordcount[cat][word] + 1) / float(self.denominator[cat])\n",
    "\n",
    "  def scoreCount(self, doc, cat):\n",
    "    \"\"\"文書が与えられたときのカテゴリの事後確率の対数 log(P(cat|doc)) を求める\"\"\"\n",
    "    total = sum(self.catcount.values())  # 総文書数\n",
    "    score = math.log(float(self.catcount[cat]) / total)  # log P(cat)\n",
    "    for word in doc:\n",
    "    # logをとるとかけ算は足し算になる\n",
    "      score += math.log(self.wordProb(word, cat))  # log P(word|cat)\n",
    "    return score\n",
    "\n",
    "  def saveTrain(self):\n",
    "    category_f = open(\"categories.dump\", \"w\")\n",
    "    #pickle.dump(self.categories, category_f) \n",
    "    pickle.dump(\"self.categories\", category_f) \n",
    "    category_f.close()\n",
    "    return 1\n",
    "\n",
    "  def __str__(self):\n",
    "    total = sum(self.catcount.values())  # 総文書数\n",
    "    return \"documents: %d, vocabularies: %d, categories: %d\" % (total, len(self.vocabularies), len(self.categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "documents: 4, vocabularies: 6, categories: 2\n",
      "P(Chinese|yes) =  0.42857142857142855\n",
      "P(Tokyo|yes) =  0.07142857142857142\n",
      "P(Japan|yes) =  0.07142857142857142\n",
      "P(Chinese|no) =  0.2222222222222222\n",
      "P(Tokyo|no) =  0.2222222222222222\n",
      "P(Japan|no) =  0.2222222222222222\n",
      "log P(yes|test) = -8.10769031284391\n",
      "log P(no|test) = -8.906681345001262\n",
      "yes\n"
     ]
    }
   ],
   "source": [
    "# Introduction to Information Retrieval 13.2の例題\n",
    "data = [[\"yes\", \"Chinese\", \"Beijing\", \"Chinese\"],\n",
    "[\"yes\", \"Chinese\", \"Chinese\", \"Shanghai\"],\n",
    "[\"yes\", \"Chinese\", \"Macao\"],\n",
    "[\"no\", \"Tokyo\", \"Japan\", \"Chinese\"]]\n",
    "# ナイーブベイズ分類器を訓練\n",
    "nb = NaiveBayes()\n",
    "nb.train(data)\n",
    "print (nb)\n",
    "print (\"P(Chinese|yes) = \", nb.wordProb(\"Chinese\", \"yes\"))\n",
    "print (\"P(Tokyo|yes) = \", nb.wordProb(\"Tokyo\", \"yes\"))\n",
    "print (\"P(Japan|yes) = \", nb.wordProb(\"Japan\", \"yes\"))\n",
    "print (\"P(Chinese|no) = \", nb.wordProb(\"Chinese\", \"no\"))\n",
    "print (\"P(Tokyo|no) = \", nb.wordProb(\"Tokyo\", \"no\"))\n",
    "print (\"P(Japan|no) = \", nb.wordProb(\"Japan\", \"no\"))\n",
    "# テストデータのカテゴリを予測\n",
    "test = [\"Chinese\", \"Chinese\", \"Chinese\", \"Tokyo\", \"Japan\"]\n",
    "print (\"log P(yes|test) =\", nb.scoreCount(test, \"yes\"))\n",
    "print (\"log P(no|test) =\", nb.scoreCount(test, \"no\"))\n",
    "print (nb.classify(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not bytes",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-e9f3aa138a7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-22-bd64fb429d50>\u001b[0m in \u001b[0;36msaveTrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;31m#pickle.dump(\"\"\"self.categories\"\"\", category_f)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'key'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m     \u001b[0mcategory_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: write() argument must be str, not bytes"
     ]
    }
   ],
   "source": [
    "nb.saveTrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
