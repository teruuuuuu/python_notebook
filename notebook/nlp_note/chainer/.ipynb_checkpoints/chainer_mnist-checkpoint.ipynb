{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import six\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from chainer import cuda, Variable, FunctionSet, optimizers\n",
    "import chainer.functions  as F\n",
    "import sys\n",
    "\n",
    "plt.style.use('ggplot')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fetch MNIST dataset\n"
     ]
    }
   ],
   "source": [
    "# 確率的勾配降下法で学習させる際の１回分のバッチサイズ\n",
    "batchsize = 100\n",
    "\n",
    "# 学習の繰り返し回数\n",
    "n_epoch   = 20\n",
    "\n",
    "# 中間層の数\n",
    "n_units   = 1000\n",
    "\n",
    "# MNISTの手書き数字データのダウンロード\n",
    "# #HOME/scikit_learn_data/mldata/mnist-original.mat にキャッシュされる\n",
    "print('fetch MNIST dataset')\n",
    "mnist = fetch_mldata('MNIST original')\n",
    "# mnist.data : 70,000件の784次元ベクトルデータ\n",
    "mnist.data   = mnist.data.astype(np.float32)\n",
    "mnist.data  /= 255     # 0-1のデータに変換\n",
    "\n",
    "# mnist.target : 正解データ（教師データ）\n",
    "mnist.target = mnist.target.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1072d5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAABHJJREFUeJzt3b9KI1EYQPHJumWwESsLQRDFFDZaaKFY2Fn7AlaiL6CN\nIBaCte+ggoVVGisRQbQNimhhaaOCoIJgtnIh3KvJbubM5M/5VctnlrnF4YZkxmuhWq1WEwn0K+8F\nqPP9GFmlUslkEV6nda+TxjWMzOvg1/DtUjgjE67gp0vRftd7QaFQyGId6gDf7Ve+XQpnZMIZmXBG\nJpyRCWdkwhmZcEYmnJEJZ2TCGZlwNfcuK5VKzfNDi4uLmS9I7e3g4ODvv0ulUlIqleo/heENcjXK\nG+TKjZEJZ2TCGZlwdZ+MFWd4eDiY3dzcBLPt7e1gtra2hqyJ4E4mnJEJZ2TCGZlwRiackQnnVxg5\nKhaLwezz8zOYTU9PZ7EcjDuZcEYmnJEJZ2TCGZlwfrrM0erqakOve3x8hFfCcicTzsiEMzLhjEw4\nIxPOT5cZGB0djc7n5uaC2dvbWzDb2dlJfU1ZcicTzsiEMzLhjEw4IxPOo6My0NfXF50PDg4Gs/X1\n9WB2dnaW+poosaOjaiL7Gkr/K7Yx+XYpnJEJZ2TCGZlw3rvMwMXFRXReLpeD2d3dHb2czLmTCWdk\nwhmZcEYmnJEJZ2TC+RVGynZ3d4PZy8tL9LWnp6fB7Pj4OPU15c2dTDgjE87IhDMy4YxMOD9dNmF8\nfDyYLS8vB7Pv/tjo0tJSMHt+fm5+YS3GnUw4IxPOyIQzMuGMTDg/XTZha2urode9vr5G51dXV2ku\np2W5kwlnZMIZmXBGJpyRCefRUQ2anJwMZrOzsw39342Njej8/Py8qTW1Io+OEs6jo5QLIxPOyIQz\nMuG8d9mgqampYFYsFoPZx8dHMDs5OUHW1C7cyYQzMuGMTDgjE87IhDMy4fwKo0Hz8/PBLPZLu3t7\ne8Hs8vISWVO7cCcTzsiEMzLhjEw4IxOuUP3uXKOvFxQKWa2lZfT29gaz29vbYBb7i7w9PT3ImtrB\ndym5kwlnZMIZmXBGJpyRCee9y4iVlZVgFvsk+fDwkMVy2p47mXBGJpyRCWdkwhmZcF1/dFR/f38w\ni/3pmpjNzc20l9P2PDpKOI+OUi6MTDgjE87IhOuaJ2NjnyKTpPbT0JeZmZlgdn9/H8zGxsaC2fv7\n+3+srjP4ZKxyY2TCGZlwRiackQlnZMJ1zePXExMT0Xns64pyuRzMDg8Pg1k3f13xL9zJhDMy4YxM\nOCMTzsiE65ob5EdHR9H5wsJCMBsZGQlmsaOjVMsb5MqNkQlnZMIZmXBGJlxH3rscGBgIZrFHpZUN\ndzLhjEw4IxPOyIQzMuE68uiooaGhhmZJkiTX19fB7OnpKfU1dQuPjhLOo6OUCyMTzsiEMzLhuubJ\nWPF8Mla5MTLhjEw4IxPOyIQzMuGMTDgjE87IhDMy4YxMOCMTzsiEMzLhjEw4IxPOyIQzMuGMTDgj\nE87IhDMy4YxMOCMTru7RUXV+91eqETs6Kqn+YH9//6cfp8brtO510riGb5fCGZlwP0aW1amLXqd1\nr5PGNeqe6iM1y7dL4f4AbiZk/SsGRP0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1072d5860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJkAAAC1CAYAAABMMl33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nynedINbI+0gcUCzeLiH3P0DZ6BOtSn0CAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1072d5f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 手書き数字データを描画する関数\n",
    "def draw_digit(data):\n",
    "    size = 28\n",
    "    plt.figure(figsize=(2.5, 3))\n",
    "\n",
    "    X, Y = np.meshgrid(range(size),range(size))\n",
    "    Z = data.reshape(size,size)   # convert from vector to 28x28 matrix\n",
    "    Z = Z[::-1,:]             # flip vertical\n",
    "    plt.xlim(0,27)\n",
    "    plt.ylim(0,27)\n",
    "    plt.pcolor(X, Y, Z)\n",
    "    plt.gray()\n",
    "    plt.tick_params(labelbottom=\"off\")\n",
    "    plt.tick_params(labelleft=\"off\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "draw_digit(mnist.data[5])\n",
    "draw_digit(mnist.data[12345])\n",
    "draw_digit(mnist.data[33456])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 学習用データを N個、検証用データを残りの個数と設定\n",
    "N = 60000\n",
    "x_train, x_test = np.split(mnist.data,   [N])\n",
    "y_train, y_test = np.split(mnist.target, [N])\n",
    "N_test = y_test.size\n",
    "\n",
    "# Prepare multi-layer perceptron model\n",
    "# 多層パーセプトロンモデルの設定\n",
    "# 入力 784次元、出力 10次元\n",
    "model = FunctionSet(l1=F.Linear(784, n_units),\n",
    "                    l2=F.Linear(n_units, n_units),\n",
    "                    l3=F.Linear(n_units, 10))\n",
    "\n",
    "# Neural net architecture\n",
    "# ニューラルネットの構造\n",
    "def forward(x_data, y_data, train=True):\n",
    "    x, t = Variable(x_data), Variable(y_data)\n",
    "    h1 = F.dropout(F.relu(model.l1(x)),  train=train)\n",
    "    h2 = F.dropout(F.relu(model.l2(h1)), train=train)\n",
    "    y  = model.l3(h2)\n",
    "    # 多クラス分類なので誤差関数としてソフトマックス関数の\n",
    "    # 交差エントロピー関数を用いて、誤差を導出\n",
    "    return F.softmax_cross_entropy(y, t), F.accuracy(y, t)\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = optimizers.Adam()\n",
    "optimizer.setup(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "train mean loss=7.8447349274655185, accuracy=0.6937833340466022\n",
      "test  mean loss=6.153371401589271, accuracy=0.8470999991893768"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "train_acc  = []\n",
    "test_loss = []\n",
    "test_acc  = []\n",
    "\n",
    "l1_W = []\n",
    "l2_W = []\n",
    "l3_W = []\n",
    "\n",
    "# Learning loop\n",
    "for epoch in six.moves.range(1, n_epoch + 1):\n",
    "    print ('epoch', epoch)\n",
    "\n",
    "    # training\n",
    "    # N個の順番をランダムに並び替える\n",
    "    perm = np.random.permutation(N)\n",
    "    sum_accuracy = 0\n",
    "    sum_loss = 0\n",
    "    # 0〜Nまでのデータをバッチサイズごとに使って学習\n",
    "    for i in six.moves.range(0, N, batchsize):\n",
    "        x_batch = x_train[perm[i:i+batchsize]]\n",
    "        y_batch = y_train[perm[i:i+batchsize]]\n",
    "\n",
    "        # 勾配を初期化\n",
    "        optimizer.zero_grads()\n",
    "        # 順伝播させて誤差と精度を算出\n",
    "        loss, acc = forward(x_batch, y_batch)\n",
    "        # 誤差逆伝播で勾配を計算\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        sum_loss     += float(cuda.to_cpu(loss.data)) * batchsize\n",
    "        sum_accuracy += float(cuda.to_cpu(acc.data)) * batchsize\n",
    "\n",
    "    # 訓練データの誤差と、正解精度を表示\n",
    "    print ('train mean loss={}, accuracy={}'.format(sum_loss / N, sum_accuracy / N))\n",
    "\n",
    "    train_loss.append(sum_loss / N)\n",
    "    train_acc.append(sum_accuracy / N)\n",
    "\n",
    "    # evaluation\n",
    "    # テストデータで誤差と、正解精度を算出し汎化性能を確認\n",
    "    sum_accuracy = 0\n",
    "    sum_loss     = 0\n",
    "    for i in six.moves.range(0, N_test, batchsize):\n",
    "        x_batch = x_test[i:i+batchsize]\n",
    "        y_batch = y_test[i:i+batchsize]\n",
    "\n",
    "        # 順伝播させて誤差と精度を算出\n",
    "        loss, acc = forward(x_batch, y_batch, train=False)\n",
    "\n",
    "        sum_loss     += float(cuda.to_cpu(loss.data)) * batchsize\n",
    "        sum_accuracy += float(cuda.to_cpu(acc.data)) * batchsize\n",
    "\n",
    "    # テストデータでの誤差と、正解精度を表示\n",
    "    print('test  mean loss={}, accuracy={}'.format(sum_loss / N_test, sum_accuracy / N_test))\n",
    "    test_loss.append(sum_loss / N_test)\n",
    "    test_acc.append(sum_accuracy / N_test)\n",
    "\n",
    "    # 学習したパラメーターを保存\n",
    "    l1_W.append(model.l1.W)\n",
    "    l2_W.append(model.l2.W)\n",
    "    l3_W.append(model.l3.W)\n",
    "\n",
    "# 精度と誤差をグラフ描画\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(len(train_acc)), train_acc)\n",
    "plt.plot(range(len(test_acc)), test_acc)\n",
    "plt.legend([\"train_acc\",\"test_acc\"],loc=4)\n",
    "plt.title(\"Accuracy of digit recognition.\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
