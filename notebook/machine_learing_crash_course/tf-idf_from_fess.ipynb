{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import functools as f\n",
    "from janome.tokenizer import Tokenizer\n",
    "from janome.tokenizer import Tokenizer\n",
    "from janome.analyzer import Analyzer\n",
    "from janome.charfilter import *\n",
    "from janome.tokenfilter import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "es = Elasticsearch(\"http://127.0.0.1:9201\")\n",
    "def scroll(index, doc_type, query_body, page_size=100, scroll='2m'):\n",
    "    page = es.search(index=index, doc_type=doc_type, scroll=scroll, size=page_size, body=query_body)\n",
    "    sid = page['_scroll_id']\n",
    "    scroll_size = page['hits']['total']\n",
    "    total_pages = math.ceil(scroll_size/page_size)\n",
    "    page_counter = 0\n",
    "    # Start scrolling\n",
    "    while (scroll_size > 0):\n",
    "        # Get the number of results that we returned in the last scroll\n",
    "        scroll_size = len(page['hits']['hits'])\n",
    "        if scroll_size>0:\n",
    "            yield total_pages, page_counter, scroll_size, page\n",
    "        # get next page\n",
    "        page = es.scroll(scroll_id = sid, scroll = '2m')\n",
    "        page_counter += 1\n",
    "        # Update the scroll ID\n",
    "        sid = page['_scroll_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wordToDicGen(tokenizer, char_filters, token_filters, stop_words):\n",
    "    def wordToDic(text):\n",
    "        dic = dict()\n",
    "        for token in Analyzer(char_filters, tokenizer, token_filters).analyze(text):\n",
    "            if token.base_form in stop_words:\n",
    "                continue\n",
    "            if token.base_form in dic:\n",
    "                dic[token.base_form] = dic[token.base_form] + 1\n",
    "            else:\n",
    "                dic[token.base_form] = 1\n",
    "        return dic\n",
    "    return wordToDic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "char_filters = [UnicodeNormalizeCharFilter()]\n",
    "tokenizer = Tokenizer()\n",
    "token_filters = [CompoundNounFilter(), POSStopFilter(['記号','助詞', '助動詞', '助動詞']), LowerCaseFilter()]\n",
    "stop_words=set([\"する\", \"れる\", \"こと\", \"いる\", \"行う\", \"できる\", \"場合\", \"の\", \"ない\", \"みる\", \"使う\", \"より\", \"なる\"])\n",
    "wordToDic = wordToDicGen(tokenizer, char_filters, token_filters, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TfIdf():\n",
    "    doc_num=0\n",
    "    word_counter = dict()\n",
    "    \n",
    "    def addDocument(self, wordCountDic):\n",
    "        self.doc_num += 1\n",
    "        for key in wordCountDic:\n",
    "            if key in self.word_counter:\n",
    "                self.word_counter[key] += 1\n",
    "            else:\n",
    "                self.word_counter[key] = 1\n",
    "\n",
    "    def answer(self, wordCountDic):\n",
    "        ans = dict()\n",
    "        document_words_sum = f.reduce(lambda x,y:x+y, list(wordCountDic.values()))\n",
    "        for word in wordCountDic:\n",
    "            tf = self.tf(document_words_sum, wordCountDic[word])\n",
    "            idf = self.idf(word)\n",
    "            ans[word] = tf*idf\n",
    "        return ans\n",
    "    \n",
    "    def tf(self, document_words_sum, word_num):\n",
    "        return word_num / document_words_sum\n",
    "    \n",
    "    def idf(self, word):\n",
    "        return math.log(float(self.doc_num / self.word_counter[word]), math.e) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tfidf = TfIdf()\n",
    "index = 'fess.20180701'\n",
    "doc_type = 'doc'\n",
    "query = { \"query\": { \"match_all\": {} }}\n",
    "page_size =30\n",
    "\n",
    "currrent_volume=0\n",
    "for total_pages, page_counter, page_items, page_data in scroll(index, doc_type, query, page_size=page_size):\n",
    "    for data in page_data['hits']['hits']:\n",
    "        tfidf.addDocument(wordToDic(data['_source']['content']))\n",
    "    currrent_volume += page_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://gigazine.net/news/20180706-china-ap1000-epr/\n",
      "原子力産業 0.023317488109853554\n",
      "遅れる 0.01886515867249546\n",
      "ap1000 0.018473965793423773\n",
      "新型原子炉 0.017488116082390166\n",
      "原子力発電所 0.017488116082390166\n",
      "wh 0.017488116082390166\n",
      "東芝 0.017488116082390166\n",
      "アメリカ 0.015243532167490574\n",
      "中国 0.014023731901107834\n",
      "最 0.013274455410293236\n",
      "https://gigazine.net/news/20180706-virus-desides-mining-or-ransomware/\n",
      "ファイル 0.03633063623601737\n",
      "カスペルスキー 0.03265374682807244\n",
      "マイニングマルウェア 0.026122997462457952\n",
      "コンピューター 0.021134973450343948\n",
      "侵入 0.019592248096843467\n",
      "身代金 0.019592248096843467\n",
      "暗号化 0.017287991110333946\n",
      "ランサムウェア 0.016922932055221898\n",
      "マルウェア 0.015427253535004832\n",
      "攻撃 0.015087760100809063\n",
      "https://gigazine.net/news/20180706-london-police-facial-recognition/\n",
      "afs 0.03595993869441478\n",
      "運用 0.024244676575199242\n",
      "犯罪容疑者 0.023973292462943184\n",
      "イギリス 0.019090283152333857\n",
      "98% 0.01797996934720739\n",
      "テスト 0.01797996934720739\n",
      "ロンドン警視庁 0.01797996934720739\n",
      "警察 0.016303568082312883\n",
      "顔認識機能 0.01581388440795756\n",
      "監視カメラ 0.014546805945119546\n",
      "https://gigazine.net/news/20180706-mit-cheetah-progress/\n",
      "ボストン・ダイナミクス 0.045936847833184545\n",
      "...... 0.025717530837217364\n",
      "障害物 0.02525171162947315\n",
      "cheetah 0.024033452280351385\n",
      "足 0.018582746117517982\n",
      "飛び越える 0.017226317937444207\n",
      "走行 0.017226317937444207\n",
      "ジャンプ 0.016543522070547958\n",
      "3世代 0.01515102697768389\n",
      "抜群 0.01515102697768389\n",
      "https://gigazine.net/news/20180706-customers-cancel-subscriptions-online-law/\n",
      "サービス 0.026082951604456672\n",
      "オンライン上 0.023532066221293925\n",
      "提供 0.0195622137033425\n",
      "明確 0.019038764427150325\n",
      "カリフォルニア州 0.017649049665970442\n",
      "cancel 0.017649049665970442\n",
      "自動更新型 0.017649049665970442\n",
      "提示 0.017649049665970442\n",
      "had 0.017649049665970442\n",
      "to 0.016061938498019724\n",
      "https://gigazine.net/news/20180705-mystery-of-kentucky-meat-shower/\n",
      "ハゲワシ 0.03448705409254564\n",
      "肉 0.029324503159288345\n",
      "gohde氏 0.022991369395030426\n",
      "motherboard 0.01724352704627282\n",
      "瓶 0.01724352704627282\n",
      "降る 0.01583149139611712\n",
      "謎 0.015215504663540665\n",
      "仮説 0.015166162868770486\n",
      "雨事件 0.013214519403227284\n",
      "? 0.011876498424664378\n",
      "https://gigazine.net/news/20180705-mario-macaroni-and-cheese/\n",
      "マカロニ&チーズ 0.06726319468020031\n",
      "マリオ 0.05691501088324641\n",
      "恐竜 0.03767518086505781\n",
      "スーパーマリオワールド 0.03104455139086168\n",
      "2dアニメーション 0.03104455139086168\n",
      "ヨッシー 0.025870459492384732\n",
      "舌 0.025870459492384732\n",
      "クッパ 0.025870459492384732\n",
      "少年 0.023564545845250764\n",
      "パッケージ 0.02093065603614323\n",
      "https://gigazine.net/news/20180701-gigazine-manga/\n",
      "描く 0.024681107815303693\n",
      "こちら 0.021314858009726056\n",
      "募集要項 0.01687809246714378\n",
      "小物 0.016689166616697216\n",
      "イラスト 0.01656713578847448\n",
      "gigazineマンガ大賞 0.014635680832971138\n",
      "gigazineシークレットクラブ 0.014600558020194318\n",
      "最後 0.01387370921092746\n",
      "1話 0.01387370921092746\n",
      "事 0.013502473973715024\n",
      "https://gigazine.net/news/20180705-kfc-red-hot-crispy-twister/\n",
      "レッドホットクリスピー 0.040414592434020194\n",
      "レッドホットツイスター 0.03730577763140326\n",
      "ケンタッキー 0.0335512088288156\n",
      "野菜 0.02249811226206441\n",
      "食べる 0.02121156478528745\n",
      "衣 0.018741336127382296\n",
      "マヨソース 0.018741336127382296\n",
      "骨 0.01865288881570163\n",
      "サクサク 0.018300659361172145\n",
      "辛口チキン 0.01554407401308469\n",
      "https://gigazine.net/news/20180705-virtue-labeling/\n",
      "ラベル付け 0.10242459318533002\n",
      "プラシーボ効果 0.035625945455766965\n",
      "ラベル 0.03525076400535431\n",
      "研究 0.032018474274988856\n",
      "寄付 0.027042079442640712\n",
      "美徳ラベリング 0.02437724672237786\n",
      "人 0.020651131333006677\n",
      "もの 0.018290081388115286\n",
      "効果 0.01818100961931576\n",
      "ミラー氏 0.017812972727883482\n"
     ]
    }
   ],
   "source": [
    "page_size =1\n",
    "\n",
    "currrent_volume=0\n",
    "for total_pages, page_counter, page_items, page_data in scroll(index, doc_type, query, page_size=page_size):\n",
    "    for data in page_data['hits']['hits']:\n",
    "        print(data['_source']['url'])\n",
    "        for k, v in sorted(tfidf.answer(wordToDic(data['_source']['content'])).items(), key=lambda x: -x[1])[:10]:\n",
    "            print(k, v)\n",
    "    currrent_volume += page_items\n",
    "    if currrent_volume >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a={\"b\":1, \"c\":2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
